# Autonomous Incident Commander

AI-powered real-time incident investigation system using Multi-Agent Reasoning and CloudWatch integration.

## ğŸ¯ Purpose

Analyzes CloudWatch logs, metrics, and deployment history to automatically diagnose incidents and generate Root Cause Analysis (RCA) reports.

## ğŸš€ Quick Start

### Prerequisites

- Python 3.12+
- [uv](https://github.com/astral-sh/uv) package manager
- AWS CLI configured with credentials
- OpenAI API key (for LLM agents)
- Terraform (for deployment)

### Setup

```bash
# Install dependencies with uv
uv sync

# Activate virtual environment
source .venv/bin/activate

# Configure environment
cp .env.example .env
# Edit .env and add your OpenAI API key

# Run tests
uv run pytest
```

### Deploy to AWS

```bash
# Package Lambda
bash scripts/package.sh

# Deploy with Terraform
cd terraform
terraform init
terraform plan
terraform apply
```

## ğŸ“¦ Project Structure

```
incident-commander/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ commander.py        # Orchestrator agent
â”‚   â”‚   â”œâ”€â”€ logs_agent.py       # Forensic log analyzer
â”‚   â”‚   â”œâ”€â”€ metrics_agent.py    # Performance analyst
â”‚   â”‚   â””â”€â”€ deploy_agent.py     # Deployment historian
â”‚   â”œâ”€â”€ nodes/
â”‚   â”‚   â”œâ”€â”€ detect.py           # DETECT node
â”‚   â”‚   â”œâ”€â”€ investigate.py      # INVESTIGATE node
â”‚   â”‚   â””â”€â”€ report.py           # REPORT node
â”‚   â”œâ”€â”€ toolkits/
â”‚   â”‚   â”œâ”€â”€ logs_toolkit.py     # CloudWatch Logs queries
â”‚   â”‚   â”œâ”€â”€ metrics_toolkit.py  # CloudWatch Metrics
â”‚   â”‚   â””â”€â”€ deploy_toolkit.py   # CloudTrail integration
â”‚   â””â”€â”€ lambda_handler.py       # Main Lambda entry point
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/                   # Unit tests
â”‚   â””â”€â”€ integration/            # Integration tests
â”œâ”€â”€ terraform/
â”‚   â””â”€â”€ modules/
â”‚       â”œâ”€â”€ lambda/             # Commander Lambda
â”‚       â””â”€â”€ iam/                # IAM roles & policies
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ package.sh              # Deployment packaging
â”œâ”€â”€ pyproject.toml              # uv project config
â”œâ”€â”€ .env.example                # Environment template
â””â”€â”€ README.md
```

## ğŸ¤– Agent Architecture

### Commander Agent
- Orchestrates investigation workflow
- Delegates to specialized agents
- Synthesizes findings into RCA

### Specialized Agents
1. **Logs Agent** - Searches CloudWatch Logs for errors
2. **Metrics Agent** - Analyzes performance metrics & spikes
3. **Deploy Agent** - Correlates deployments with incidents

## ğŸ”¬ Investigation Flow

```
DETECT â†’ PLAN â†’ INVESTIGATE â†’ AGGREGATE â†’ DECIDE â†’ ACT â†’ REPORT
```

1. **DETECT**: Receive alert (latency spike, error rate, etc.)
2. **PLAN**: Create investigation strategy
3. **INVESTIGATE**: Parallel agent execution (Logs + Metrics + Deploy)
4. **AGGREGATE**: Combine findings
5. **DECIDE**: Determine root cause with confidence score
6. **ACT**: Generate recommended actions
7. **REPORT**: Create RCA markdown report

## ğŸ§ª Testing

```bash
# Run all tests
uv run pytest

# Run with coverage
uv run pytest --cov=src --cov-report=html

# Run specific test suite
uv run pytest tests/unit/test_agents.py -v

# Integration tests (requires AWS credentials)
uv run pytest tests/integration/ -v
```

## ğŸ“Š Usage

### Trigger Investigation

```bash
# Via API (after deployment)
curl -X POST "$LAMBDA_URL/investigate" \
  -H "Content-Type: application/json" \
  -d '{
    "service": "demo-checkout-service",
    "metric": "error_rate",
    "current_value": 0.50,
    "threshold": 0.05,
    "timestamp": "2026-02-06T14:30:00Z"
  }'
```

### Local Testing

```bash
# Test with sample incident
uv run python -m src.lambda_handler --incident tests/fixtures/sample_incident.json
```

## ğŸ”§ Configuration

Copy `.env.example` to `.env`:

```bash
OPENAI_API_KEY=sk-...
AWS_REGION=us-east-1
LOG_GROUP_NAME=/aws/lambda/demo-checkout-service
FUNCTION_NAME=demo-checkout-service
```

## ğŸ› ï¸ Technologies

- **LangGraph** - Agent orchestration
- **LangChain** - LLM integration
- **OpenAI GPT-4** - Reasoning engine
- **AWS Lambda** - Serverless compute
- **CloudWatch** - Log/metrics data source
- **Boto3** - AWS SDK

## ğŸ“ License

MIT
